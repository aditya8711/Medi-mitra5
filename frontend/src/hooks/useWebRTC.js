// Fresh WebRTC Hook - Simplified for Demo
import { useState, useEffect, useRef } from 'react';
import { getSocket } from '../utils/socket';

export default function useWebRTC(user) {
  // States
  const [callState, setCallState] = useState('idle'); // idle, incoming, active
  const [incomingOffer, setIncomingOffer] = useState(null);
  
  // Refs
  const localVideoRef = useRef(null);
  const remoteVideoRef = useRef(null);
  const pcRef = useRef(null);
  const socketRef = useRef(null);
  const localStreamRef = useRef(null);
  const remoteUserIdRef = useRef(null);
  const queuedCandidatesRef = useRef([]); // Queue ICE candidates until remote description is set
  const pendingRemoteStreamRef = useRef(null); // Store remote stream when video element isn't ready
  const lastRemoteStreamIdRef = useRef(null); // Track the stream already attached to avoid duplicate loads

  const ensureRemotePlayback = (videoEl) => {
    if (!videoEl) {
      return;
    }

    const attemptPlay = () => {
      if (!videoEl.isConnected) {
        console.warn('‚è≠Ô∏è Skipping remote autoplay - element not in DOM');
        return;
      }
      videoEl.play().catch(err => {
        console.warn('‚ö†Ô∏è Remote video autoplay failed (attempt):', err);
        setTimeout(() => {
          if (!videoEl.isConnected) {
            console.warn('‚è≠Ô∏è Skipping remote autoplay retry - element not in DOM');
            return;
          }
          videoEl.play().catch(e => console.warn('‚ö†Ô∏è Retry remote play failed:', e));
        }, 250);
      });
    };

    if (videoEl.readyState >= 1) {
      attemptPlay();
    } else {
      videoEl.addEventListener('loadedmetadata', attemptPlay, { once: true });
      setTimeout(() => {
        if (!videoEl.isConnected) {
          console.warn('‚è≠Ô∏è Skipping remote autoplay fallback - element not in DOM');
          return;
        }
        if (videoEl.readyState < 1) {
          attemptPlay();
        }
      }, 500);
    }
  };

  // Enhanced ICE servers for better connectivity
  const iceServers = [
    { urls: "stun:stun.l.google.com:19302" },
    { urls: "stun:stun1.l.google.com:19302" },
    { urls: "stun:stun.cloudflare.com:3478" },
    { 
      urls: ["turn:relay1.expressturn.com:3478?transport=udp", "turn:relay1.expressturn.com:3478?transport=tcp"],
      username: "efCZWX3MTI071W2V6N", 
      credential: "mGWa8dVKpR4FgpE" 
    },
    {
      urls: ["turn:openrelay.metered.ca:80", "turn:openrelay.metered.ca:443"],
      username: "openrelayproject",
      credential: "openrelayproject"
    }
  ];

  // Initialize
  useEffect(() => {
    socketRef.current = getSocket();

    // Register user - join room with their ID so they can receive WebRTC signals
    if (user?._id || user?.id) {
      const userId = user._id || user.id;
      console.log('üè† Joining room for user:', userId);
      socketRef.current.emit("join", userId);
      
      // Also emit register for backup room joining
      socketRef.current.emit("register", userId);
      console.log('üìù Backup registration sent for user:', userId);
    }

    // Initialize local media stream for patients to ensure camera/mic is ready
    if (user?.role === 'patient') {
      console.log('üë§ Patient detected - initializing camera/microphone...');
      initializeLocalMedia();
    }

    // Socket listeners
    socketRef.current.on("webrtc:offer", handleOffer);
    socketRef.current.on("webrtc:answer", handleAnswer);
    socketRef.current.on("webrtc:ice-candidate", handleIceCandidate);
    
    // Re-join room on socket reconnection
    socketRef.current.on("connect", () => {
      if (user?._id || user?.id) {
        const userId = user._id || user.id;
        console.log('üîÑ Socket reconnected, re-joining room:', userId);
        socketRef.current.emit("join", userId);
        socketRef.current.emit("register", userId);
      }
    });
    
    // Debug: Log WebRTC listener status periodically
    const debugInterval = setInterval(() => {
      if (socketRef.current) {
        console.log('üîç WebRTC Debug Check:', {
          socketConnected: socketRef.current.connected,
          hasOfferListener: socketRef.current.listeners('webrtc:offer').length > 0,
          callState: callState,
          userRole: user?.role,
          userId: user?._id || user?.id
        });
      }
    }, 10000); // Every 10 seconds

    return () => {
      clearInterval(debugInterval);
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => track.stop());
      }
      if (pcRef.current) {
        pcRef.current.close();
      }
    };
  }, [user]);

  // Handle incoming offer
  const handleOffer = async (payload) => {
    console.log('ÔøΩ WEBRTC OFFER RECEIVED! üö®');
    console.log('ÔøΩüì• Incoming WebRTC offer from:', payload.from);
    console.log('üìã Offer payload:', payload);
    console.log('üìã Current call state:', callState);
    console.log('üìã Current user ID:', user?._id || user?.id);
    console.log('üìã Socket connected:', socketRef.current?.connected);
    
    // Check if we're already in a call to prevent duplicate processing
    if (callState !== 'idle') {
      console.log('‚ö†Ô∏è IGNORING OFFER: Already in call state:', callState);
      return;
    }
    
    setIncomingOffer(payload);
    setCallState('incoming');
    remoteUserIdRef.current = payload.from;
    
    console.log('‚úÖ OFFER PROCESSED: State changed from idle to incoming - ready to answer');
  };

  // Handle answer
  const handleAnswer = async (payload) => {
    try {
      console.log('üì• Received answer');
      if (pcRef.current && payload?.answer) {
        // Check signaling state before setting remote description
        const currentState = pcRef.current.signalingState;
        console.log('üìã Current signaling state:', currentState);
        
        if (currentState === 'have-local-offer') {
          await pcRef.current.setRemoteDescription(new RTCSessionDescription(payload.answer));
          setCallState('active');
          
          // Process any queued ICE candidates
          console.log(`üì• Processing ${queuedCandidatesRef.current.length} queued ICE candidates`);
          for (const candidate of queuedCandidatesRef.current) {
            try {
              await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
              console.log('‚úÖ Queued ICE candidate processed');
            } catch (error) {
              console.warn('‚ö†Ô∏è Failed to process queued candidate:', error);
            }
          }
          queuedCandidatesRef.current = []; // Clear queue
        } else {
          console.warn('‚ö†Ô∏è Ignoring answer - not in correct signaling state:', currentState);
        }
      }
    } catch (error) {
      console.error('‚ùå Error processing answer:', error);
    }
  };

  // Handle ICE candidate with queuing
  const handleIceCandidate = async (payload) => {
    try {
      if (pcRef.current && payload?.candidate) {
        console.log('üì• Adding ICE candidate:', payload.candidate.candidate?.substring(0, 50) + '...');
        
        // Check if remote description is set
        if (pcRef.current.remoteDescription) {
          await pcRef.current.addIceCandidate(new RTCIceCandidate(payload.candidate));
          console.log('‚úÖ ICE candidate added successfully');
        } else {
          // Queue candidate until remote description is available
          console.log('üì¶ Queueing ICE candidate - remote description not set yet');
          queuedCandidatesRef.current.push(payload.candidate);
        }
      }
    } catch (error) {
      console.error('‚ùå Error adding ICE candidate:', error);
    }
  };

  // Recreate peer connection if closed or invalid
  const createPeerConnection = () => {
    if (pcRef.current) {
      pcRef.current.close();
    }
    
    pcRef.current = new RTCPeerConnection({ iceServers });
    
    // Set up event handlers
    pcRef.current.onicecandidate = (event) => {
      if (event.candidate && socketRef.current && remoteUserIdRef.current) {
        console.log('üì§ Sending ICE candidate');
        socketRef.current.emit("webrtc:ice-candidate", {
          candidate: event.candidate,
          to: remoteUserIdRef.current,
        });
      }
    };

    pcRef.current.ontrack = (event) => {
      console.log('üì∫ Received remote track:', event.track.kind);
      console.log('üì∫ Remote track details:', {
        trackId: event.track.id,
        trackEnabled: event.track.enabled,
        trackReadyState: event.track.readyState,
        streamsCount: event.streams.length,
        hasVideoElement: !!remoteVideoRef.current
      });
      
      if (event.streams[0]) {
        const stream = event.streams[0];
        console.log('üé• Processing remote stream:', {
          streamId: stream.id,
          videoTracks: stream.getVideoTracks().length,
          audioTracks: stream.getAudioTracks().length,
          active: stream.active
        });
        
        // Store the stream for later attachment if video element isn't ready
        pendingRemoteStreamRef.current = stream;

        const attachStream = (videoEl, s) => {
          try {
            if (videoEl.srcObject === s || lastRemoteStreamIdRef.current === s.id) {
              console.log('üîÅ Remote stream already attached, ensuring playback');
              ensureRemotePlayback(videoEl);
              return;
            }

            videoEl.srcObject = s;
            videoEl.muted = true; // keep muted for autoplay compliance
            lastRemoteStreamIdRef.current = s.id;

            ensureRemotePlayback(videoEl);
          } catch (err) {
            console.warn('‚ö†Ô∏è Error attaching remote stream:', err);
          }
        };

        if (remoteVideoRef.current) {
          console.log('‚úÖ Video element ready, attaching stream immediately');
          // schedule attachment on next tick to avoid DOM removal race
          setTimeout(() => attachStream(remoteVideoRef.current, stream), 0);
        } else {
          console.log('üì¶ Video element not ready, stream stored for later attachment');
        }
      } else {
        console.warn('‚ö†Ô∏è No stream in ontrack event');
      }
    };

    pcRef.current.oniceconnectionstatechange = () => {
      const state = pcRef.current.iceConnectionState;
      console.log('üîó ICE Connection state:', state);
      
      if (state === 'connected' || state === 'completed') {
        console.log('‚úÖ Call connected successfully!');
        setCallState('active');
      } else if (state === 'failed') {
        console.error('‚ùå ICE connection failed - checking firewall/network');
      } else if (state === 'disconnected') {
        console.warn('‚ö†Ô∏è ICE connection disconnected - may reconnect');
      } else if (state === 'checking') {
        console.log('üîç ICE checking - establishing connection...');
      }
    };

    pcRef.current.onconnectionstatechange = () => {
      const state = pcRef.current.connectionState;
      console.log('üåê Peer connection state:', state);
      
      if (state === 'failed') {
        console.error('‚ùå Peer connection failed completely');
      } else if (state === 'disconnected') {
        console.warn('‚ö†Ô∏è Peer connection disconnected');
      }
    };
  };

  // Initialize local media stream (for patients to be ready)
  const initializeLocalMedia = async () => {
    try {
      console.log('üöÄ initializeLocalMedia called for patient');
      
      if (localStreamRef.current) {
        console.log('üì± Local media already initialized');
        return;
      }

      console.log('üé• Initializing patient camera and microphone...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { width: { ideal: 1280 }, height: { ideal: 720 } }, 
        audio: { echoCancellation: true, noiseSuppression: true } 
      });
      
      localStreamRef.current = stream;
      
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        console.log('‚úÖ Patient local video stream ready');
      } else {
        console.log('üì¶ Local video element not ready, stream stored');
      }
    } catch (error) {
      console.error('‚ùå Failed to initialize patient media:', error);
      if (error.name === 'NotAllowedError') {
        console.error('üö´ Camera/microphone permission denied');
      } else if (error.name === 'NotFoundError') {
        console.error('üì∑ No camera/microphone found');
      } else if (error.name === 'NotReadableError') {
        console.error('üîí Camera/microphone already in use');
      }
    }
  };

  // Start call (for doctor)
  const startCall = async (targetUserId) => {
    try {
      console.log('üìû Starting call to:', targetUserId);
      remoteUserIdRef.current = targetUserId;
      
      // Create fresh peer connection
      createPeerConnection();
      
      // Get local media with error handling
      console.log('üé• Requesting camera and microphone access...');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      localStreamRef.current = stream;
      
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        console.log('‚úÖ Local video stream attached');
      }
      
      // Add tracks to peer connection
      stream.getTracks().forEach(track => {
        console.log('‚ûï Adding track:', track.kind, track.label);
        pcRef.current.addTrack(track, stream);
      });
      
      // Create and send offer
      console.log('üìù Creating offer...');
      const offer = await pcRef.current.createOffer();
      await pcRef.current.setLocalDescription(offer);
      console.log('‚úÖ Local description set, sending offer');
      
      const offerPayload = {
        offer,
        to: targetUserId,
        from: user?._id || user?.id
      };
      console.log('üì§ Emitting WebRTC offer:', offerPayload);
      socketRef.current.emit("webrtc:offer", offerPayload);
      
      setCallState('calling');
    } catch (error) {
      console.error('‚ùå Error starting call:', error);
      setCallState('idle');
    }
  };

  // Answer call (for patient)
  const answerCall = async () => {
    try {
      console.log('üìû Answering call');
      
      if (!incomingOffer) {
        console.error('‚ùå No incoming offer to answer');
        return;
      }
      
      // Create fresh peer connection for answering
      createPeerConnection();
      
      // Get local media
      console.log('üé• Patient requesting camera and microphone access...');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      localStreamRef.current = stream;
      
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        console.log('‚úÖ Patient local video stream attached');
      }
      
      // Add tracks to peer connection
      stream.getTracks().forEach(track => {
        console.log('‚ûï Patient adding track:', track.kind, track.label);
        pcRef.current.addTrack(track, stream);
      });
      
      // Set remote description and create answer
      console.log('üìù Setting remote description and creating answer...');
      await pcRef.current.setRemoteDescription(new RTCSessionDescription(incomingOffer.offer));
      
      // Process any queued ICE candidates now that remote description is set
      console.log(`üì• Processing ${queuedCandidatesRef.current.length} queued ICE candidates`);
      for (const candidate of queuedCandidatesRef.current) {
        try {
          await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
          console.log('‚úÖ Queued ICE candidate processed');
        } catch (error) {
          console.warn('‚ö†Ô∏è Failed to process queued candidate:', error);
        }
      }
      queuedCandidatesRef.current = []; // Clear queue
      
      const answer = await pcRef.current.createAnswer();
      await pcRef.current.setLocalDescription(answer);
      console.log('‚úÖ Answer created and local description set');
      
      // Send answer
      socketRef.current.emit("webrtc:answer", {
        answer,
        to: incomingOffer.from,
      });
      console.log('üì§ Answer sent to doctor');
      
      setCallState('active');
      setIncomingOffer(null);
    } catch (error) {
      console.error('‚ùå Error answering call:', error);
      setCallState('idle');
    }
  };

  // Retry attaching pending remote stream when video element becomes available
  const retryRemoteStreamAttachment = () => {
    if (pendingRemoteStreamRef.current && remoteVideoRef.current && !remoteVideoRef.current.srcObject) {
      console.log('üîÑ Retrying remote stream attachment');
      const stream = pendingRemoteStreamRef.current;
      console.log('üé• Attaching pending remote stream:', {
        streamId: stream.id,
        videoTracks: stream.getVideoTracks().length,
        audioTracks: stream.getAudioTracks().length,
        active: stream.active
      });

      // reuse same attachment strategy as ontrack
      setTimeout(() => {
        try {
          if (remoteVideoRef.current.srcObject === stream || lastRemoteStreamIdRef.current === stream.id) {
            console.log('üîÅ Remote stream already attached during retry, ensuring playback');
            remoteVideoRef.current.muted = true;
            ensureRemotePlayback(remoteVideoRef.current);
            return;
          }
          remoteVideoRef.current.srcObject = stream;
          // keep muted for autoplay compliance; UI can unmute later
          remoteVideoRef.current.muted = true;
          lastRemoteStreamIdRef.current = stream.id;
          ensureRemotePlayback(remoteVideoRef.current);
        } catch (err) {
          console.warn('‚ö†Ô∏è Error during retry attachment:', err);
        }
      }, 0);

      console.log('‚úÖ Pending remote stream attachment scheduled');
      return true;
    }
    return false;
  };

  // Retry local stream attachment when video element becomes available
  const retryLocalStreamAttachment = () => {
    if (localStreamRef.current && localVideoRef.current && !localVideoRef.current.srcObject) {
      console.log('üì± Attaching local stream to video element');
      localVideoRef.current.srcObject = localStreamRef.current;
      console.log('‚úÖ Local stream attached successfully');
      return true;
    }
    return false;
  };

  const unmuteRemote = () => {
    if (remoteVideoRef.current) {
      remoteVideoRef.current.muted = false;
      ensureRemotePlayback(remoteVideoRef.current);
    }
  };

  // End call
  const endCall = () => {
    console.log('üìû Ending call');
    
    // Stop local stream
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop());
      localStreamRef.current = null;
    }
    
    // Close peer connection
    if (pcRef.current) {
      pcRef.current.close();
      pcRef.current = null;
    }
    
    // Reset state
    setCallState('idle');
    setIncomingOffer(null);
    remoteUserIdRef.current = null;
    queuedCandidatesRef.current = []; // Clear queued candidates
    pendingRemoteStreamRef.current = null; // Clear pending remote stream
    lastRemoteStreamIdRef.current = null; // Reset attached stream tracker
    
    // Clear video elements
    if (localVideoRef.current) localVideoRef.current.srcObject = null;
    if (remoteVideoRef.current) remoteVideoRef.current.srcObject = null;
  };

  return {
    localVideoRef,
    remoteVideoRef,
    startCall,
    answerCall,
    endCall,
    retryRemoteStreamAttachment,
    retryLocalStreamAttachment,
    unmuteRemote,
    incomingOffer,
    callState
  };
}

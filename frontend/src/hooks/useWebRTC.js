// Fresh WebRTC Hook - Simplified for Demo
import { useState, useEffect, useRef } from 'react';
import { getSocket } from '../utils/socket';

export default function useWebRTC(user) {
  // States
  const [callState, setCallState] = useState('idle'); // idle, incoming, active
  const [incomingOffer, setIncomingOffer] = useState(null);
  
  // Refs
  const localVideoRef = useRef(null);
  const remoteVideoRef = useRef(null);
  const pcRef = useRef(null);
  const socketRef = useRef(null);
  const localStreamRef = useRef(null);
  const remoteUserIdRef = useRef(null);
  const queuedCandidatesRef = useRef([]); // Queue ICE candidates until remote description is set
  const pendingRemoteStreamRef = useRef(null); // Store remote stream when video element isn't ready

  // Enhanced ICE servers for better connectivity
  const iceServers = [
    { urls: "stun:stun.l.google.com:19302" },
    { urls: "stun:stun1.l.google.com:19302" },
    { urls: "stun:stun.cloudflare.com:3478" },
    { 
      urls: ["turn:relay1.expressturn.com:3478?transport=udp", "turn:relay1.expressturn.com:3478?transport=tcp"],
      username: "efCZWX3MTI071W2V6N", 
      credential: "mGWa8dVKpR4FgpE" 
    },
    {
      urls: ["turn:openrelay.metered.ca:80", "turn:openrelay.metered.ca:443"],
      username: "openrelayproject",
      credential: "openrelayproject"
    }
  ];

  // Initialize
  useEffect(() => {
    socketRef.current = getSocket();

    // Register user - join room with their ID so they can receive WebRTC signals
    if (user?._id || user?.id) {
      const userId = user._id || user.id;
      console.log('ðŸ  Joining room for user:', userId);
      socketRef.current.emit("join", userId);
      
      // Also emit register for backup room joining
      socketRef.current.emit("register", userId);
      console.log('ðŸ“ Backup registration sent for user:', userId);
    }

    // Initialize local media stream for patients to ensure camera/mic is ready
    if (user?.role === 'patient') {
      console.log('ðŸ‘¤ Patient detected - initializing camera/microphone...');
      initializeLocalMedia();
    }

    // Socket listeners
    socketRef.current.on("webrtc:offer", handleOffer);
    socketRef.current.on("webrtc:answer", handleAnswer);
    socketRef.current.on("webrtc:ice-candidate", handleIceCandidate);
    
    // Re-join room on socket reconnection
    socketRef.current.on("connect", () => {
      if (user?._id || user?.id) {
        const userId = user._id || user.id;
        console.log('ðŸ”„ Socket reconnected, re-joining room:', userId);
        socketRef.current.emit("join", userId);
        socketRef.current.emit("register", userId);
      }
    });
    
    // Debug: Log WebRTC listener status periodically
    const debugInterval = setInterval(() => {
      if (socketRef.current) {
        console.log('ðŸ” WebRTC Debug Check:', {
          socketConnected: socketRef.current.connected,
          hasOfferListener: socketRef.current.listeners('webrtc:offer').length > 0,
          callState: callState,
          userRole: user?.role,
          userId: user?._id || user?.id
        });
      }
    }, 10000); // Every 10 seconds

    return () => {
      clearInterval(debugInterval);
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => track.stop());
      }
      if (pcRef.current) {
        pcRef.current.close();
      }
    };
  }, [user]);

  // Handle incoming offer
  const handleOffer = async (payload) => {
    console.log('ï¿½ WEBRTC OFFER RECEIVED! ðŸš¨');
    console.log('ï¿½ðŸ“¥ Incoming WebRTC offer from:', payload.from);
    console.log('ðŸ“‹ Offer payload:', payload);
    console.log('ðŸ“‹ Current call state:', callState);
    console.log('ðŸ“‹ Current user ID:', user?._id || user?.id);
    console.log('ðŸ“‹ Socket connected:', socketRef.current?.connected);
    
    setIncomingOffer(payload);
    setCallState('incoming');
    remoteUserIdRef.current = payload.from;
    
    console.log('âœ… Offer processed, state set to incoming');
  };

  // Handle answer
  const handleAnswer = async (payload) => {
    try {
      console.log('ðŸ“¥ Received answer');
      if (pcRef.current && payload?.answer) {
        // Check signaling state before setting remote description
        const currentState = pcRef.current.signalingState;
        console.log('ðŸ“‹ Current signaling state:', currentState);
        
        if (currentState === 'have-local-offer') {
          await pcRef.current.setRemoteDescription(new RTCSessionDescription(payload.answer));
          setCallState('active');
          
          // Process any queued ICE candidates
          console.log(`ðŸ“¥ Processing ${queuedCandidatesRef.current.length} queued ICE candidates`);
          for (const candidate of queuedCandidatesRef.current) {
            try {
              await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
              console.log('âœ… Queued ICE candidate processed');
            } catch (error) {
              console.warn('âš ï¸ Failed to process queued candidate:', error);
            }
          }
          queuedCandidatesRef.current = []; // Clear queue
        } else {
          console.warn('âš ï¸ Ignoring answer - not in correct signaling state:', currentState);
        }
      }
    } catch (error) {
      console.error('âŒ Error processing answer:', error);
    }
  };

  // Handle ICE candidate with queuing
  const handleIceCandidate = async (payload) => {
    try {
      if (pcRef.current && payload?.candidate) {
        console.log('ðŸ“¥ Adding ICE candidate:', payload.candidate.candidate?.substring(0, 50) + '...');
        
        // Check if remote description is set
        if (pcRef.current.remoteDescription) {
          await pcRef.current.addIceCandidate(new RTCIceCandidate(payload.candidate));
          console.log('âœ… ICE candidate added successfully');
        } else {
          // Queue candidate until remote description is available
          console.log('ðŸ“¦ Queueing ICE candidate - remote description not set yet');
          queuedCandidatesRef.current.push(payload.candidate);
        }
      }
    } catch (error) {
      console.error('âŒ Error adding ICE candidate:', error);
    }
  };

  // Recreate peer connection if closed or invalid
  const createPeerConnection = () => {
    if (pcRef.current) {
      pcRef.current.close();
    }
    
    pcRef.current = new RTCPeerConnection({ iceServers });
    
    // Set up event handlers
    pcRef.current.onicecandidate = (event) => {
      if (event.candidate && socketRef.current && remoteUserIdRef.current) {
        console.log('ðŸ“¤ Sending ICE candidate');
        socketRef.current.emit("webrtc:ice-candidate", {
          candidate: event.candidate,
          to: remoteUserIdRef.current,
        });
      }
    };

    pcRef.current.ontrack = (event) => {
      console.log('ðŸ“º Received remote track:', event.track.kind);
      console.log('ðŸ“º Remote track details:', {
        trackId: event.track.id,
        trackEnabled: event.track.enabled,
        trackReadyState: event.track.readyState,
        streamsCount: event.streams.length,
        hasVideoElement: !!remoteVideoRef.current
      });
      
      if (event.streams[0]) {
        const stream = event.streams[0];
        console.log('ðŸŽ¥ Processing remote stream:', {
          streamId: stream.id,
          videoTracks: stream.getVideoTracks().length,
          audioTracks: stream.getAudioTracks().length,
          active: stream.active
        });
        
        // Store the stream for later attachment if video element isn't ready
        pendingRemoteStreamRef.current = stream;
        
        if (remoteVideoRef.current) {
          console.log('âœ… Video element ready, attaching stream immediately');
          remoteVideoRef.current.srcObject = stream;
          
          // Force video element to play
          remoteVideoRef.current.play().catch(e => {
            console.warn('âš ï¸ Remote video autoplay failed:', e);
          });
        } else {
          console.log('ðŸ“¦ Video element not ready, stream stored for later attachment');
        }
      } else {
        console.warn('âš ï¸ No stream in ontrack event');
      }
    };

    pcRef.current.oniceconnectionstatechange = () => {
      const state = pcRef.current.iceConnectionState;
      console.log('ðŸ”— ICE Connection state:', state);
      
      if (state === 'connected' || state === 'completed') {
        console.log('âœ… Call connected successfully!');
        setCallState('active');
      } else if (state === 'failed') {
        console.error('âŒ ICE connection failed - checking firewall/network');
      } else if (state === 'disconnected') {
        console.warn('âš ï¸ ICE connection disconnected - may reconnect');
      } else if (state === 'checking') {
        console.log('ðŸ” ICE checking - establishing connection...');
      }
    };

    pcRef.current.onconnectionstatechange = () => {
      const state = pcRef.current.connectionState;
      console.log('ðŸŒ Peer connection state:', state);
      
      if (state === 'failed') {
        console.error('âŒ Peer connection failed completely');
      } else if (state === 'disconnected') {
        console.warn('âš ï¸ Peer connection disconnected');
      }
    };
  };

  // Initialize local media stream (using doctor's reliable pattern)
  const initializeLocalMedia = async () => {
    try {
      console.log('ðŸš€ initializeLocalMedia called for patient - using doctor pattern');
      
      if (localStreamRef.current) {
        console.log('ðŸ“± Local media already initialized');
        return localStreamRef.current;
      }

      console.log('ðŸŽ¥ Patient requesting camera/microphone (doctor pattern)...');
      
      // Use exact same constraints as doctor's startCall
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      localStreamRef.current = stream;
      
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        console.log('âœ… Patient local video stream attached (doctor pattern)');
      } else {
        console.log('ðŸ“¦ Local video element not ready, stream stored for later');
      }
      
      // Log tracks like doctor does
      stream.getTracks().forEach(track => {
        console.log('âž• Patient has track:', track.kind, track.label);
      });
      
      return stream;
    } catch (error) {
      console.error('âŒ Failed to initialize patient media:', error);
      if (error.name === 'NotAllowedError') {
        console.error('ðŸš« Camera/microphone permission denied');
      } else if (error.name === 'NotFoundError') {
        console.error('ðŸ“· No camera/microphone found');
      } else if (error.name === 'NotReadableError') {
        console.error('ðŸ”’ Camera/microphone already in use');
      }
    }
  };

  // Start call (for doctor)
  const startCall = async (targetUserId) => {
    try {
      console.log('ðŸ“ž Starting call to:', targetUserId);
      remoteUserIdRef.current = targetUserId;
      
      // Create fresh peer connection
      createPeerConnection();
      
      // Get local media with error handling
      console.log('ðŸŽ¥ Requesting camera and microphone access...');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      localStreamRef.current = stream;
      
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        console.log('âœ… Local video stream attached');
      }
      
      // Add tracks to peer connection
      stream.getTracks().forEach(track => {
        console.log('âž• Adding track:', track.kind, track.label);
        pcRef.current.addTrack(track, stream);
      });
      
      // Create and send offer
      console.log('ðŸ“ Creating offer...');
      const offer = await pcRef.current.createOffer();
      await pcRef.current.setLocalDescription(offer);
      console.log('âœ… Local description set, sending offer');
      
      const offerPayload = {
        offer,
        to: targetUserId,
        from: user?._id || user?.id
      };
      console.log('ðŸ“¤ Emitting WebRTC offer:', offerPayload);
      socketRef.current.emit("webrtc:offer", offerPayload);
      
      setCallState('calling');
    } catch (error) {
      console.error('âŒ Error starting call:', error);
      setCallState('idle');
    }
  };

  // Answer call (for patient)
  const answerCall = async () => {
    try {
      console.log('ðŸ“ž Answering call');
      
      if (!incomingOffer) {
        console.error('âŒ No incoming offer to answer');
        return;
      }
      
      // Create fresh peer connection for answering
      createPeerConnection();
      
      // Get local media
      console.log('ðŸŽ¥ Patient requesting camera and microphone access...');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      localStreamRef.current = stream;
      
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        console.log('âœ… Patient local video stream attached');
      }
      
      // Add tracks to peer connection
      stream.getTracks().forEach(track => {
        console.log('âž• Patient adding track:', track.kind, track.label);
        pcRef.current.addTrack(track, stream);
      });
      
      // Set remote description and create answer
      console.log('ðŸ“ Setting remote description and creating answer...');
      await pcRef.current.setRemoteDescription(new RTCSessionDescription(incomingOffer.offer));
      
      // Process any queued ICE candidates now that remote description is set
      console.log(`ðŸ“¥ Processing ${queuedCandidatesRef.current.length} queued ICE candidates`);
      for (const candidate of queuedCandidatesRef.current) {
        try {
          await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
          console.log('âœ… Queued ICE candidate processed');
        } catch (error) {
          console.warn('âš ï¸ Failed to process queued candidate:', error);
        }
      }
      queuedCandidatesRef.current = []; // Clear queue
      
      const answer = await pcRef.current.createAnswer();
      await pcRef.current.setLocalDescription(answer);
      console.log('âœ… Answer created and local description set');
      
      // Send answer
      socketRef.current.emit("webrtc:answer", {
        answer,
        to: incomingOffer.from,
      });
      console.log('ðŸ“¤ Answer sent to doctor');
      
      setCallState('active');
      setIncomingOffer(null);
    } catch (error) {
      console.error('âŒ Error answering call:', error);
      setCallState('idle');
    }
  };

  // Retry attaching pending remote stream when video element becomes available
  const retryRemoteStreamAttachment = () => {
    if (pendingRemoteStreamRef.current && remoteVideoRef.current && !remoteVideoRef.current.srcObject) {
      console.log('ðŸ”„ Retrying remote stream attachment');
      console.log('ðŸŽ¥ Attaching pending remote stream:', {
        streamId: pendingRemoteStreamRef.current.id,
        videoTracks: pendingRemoteStreamRef.current.getVideoTracks().length,
        audioTracks: pendingRemoteStreamRef.current.getAudioTracks().length,
        active: pendingRemoteStreamRef.current.active
      });
      
      remoteVideoRef.current.srcObject = pendingRemoteStreamRef.current;
      
      // Force video element to play
      remoteVideoRef.current.play().catch(e => {
        console.warn('âš ï¸ Remote video autoplay failed:', e);
      });
      
      console.log('âœ… Pending remote stream attached successfully');
      return true;
    }
    return false;
  };

  // Retry local stream attachment when video element becomes available
  const retryLocalStreamAttachment = () => {
    if (localStreamRef.current && localVideoRef.current && !localVideoRef.current.srcObject) {
      console.log('ðŸ“± Attaching local stream to video element');
      localVideoRef.current.srcObject = localStreamRef.current;
      console.log('âœ… Local stream attached successfully');
      return true;
    }
    return false;
  };

  // End call
  const endCall = () => {
    console.log('ðŸ“ž Ending call');
    
    // Stop local stream
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop());
      localStreamRef.current = null;
    }
    
    // Close peer connection
    if (pcRef.current) {
      pcRef.current.close();
      pcRef.current = null;
    }
    
    // Reset state
    setCallState('idle');
    setIncomingOffer(null);
    remoteUserIdRef.current = null;
    queuedCandidatesRef.current = []; // Clear queued candidates
    pendingRemoteStreamRef.current = null; // Clear pending remote stream
    
    // Clear video elements
    if (localVideoRef.current) localVideoRef.current.srcObject = null;
    if (remoteVideoRef.current) remoteVideoRef.current.srcObject = null;
  };

  return {
    localVideoRef,
    remoteVideoRef,
    startCall,
    answerCall,
    endCall,
    retryRemoteStreamAttachment,
    retryLocalStreamAttachment,
    incomingOffer,
    callState
  };
}
